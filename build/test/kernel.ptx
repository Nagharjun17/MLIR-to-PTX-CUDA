//
// Generated by LLVM NVPTX Back-End
//

.version 7.1
.target sm_86
.address_size 64

	// .globl	scalar                  // -- Begin function scalar
.global .align 64 .b8 __constant_4xf32[16];
                                        // @scalar
.visible .func  (.param .b32 func_retval0) scalar(
	.param .b32 scalar_param_0,
	.param .b32 scalar_param_1
)
{
	.reg .b32 	%r<5>;

// %bb.0:
	ld.param.b32 	%r1, [scalar_param_0];
	ld.param.b32 	%r2, [scalar_param_1];
	add.rn.f32 	%r3, %r1, %r2;
	max.NaN.f32 	%r4, %r3, 0f00000000;
	st.param.b32 	[func_retval0], %r4;
	ret;
                                        // -- End function
}
	// .globl	tensor_rhs_zero         // -- Begin function tensor_rhs_zero
.visible .func  (.param .align 8 .b8 func_retval0[40]) tensor_rhs_zero(
	.param .b64 tensor_rhs_zero_param_0,
	.param .b64 tensor_rhs_zero_param_1,
	.param .b64 tensor_rhs_zero_param_2,
	.param .b64 tensor_rhs_zero_param_3,
	.param .b64 tensor_rhs_zero_param_4,
	.param .b64 tensor_rhs_zero_param_5,
	.param .b64 tensor_rhs_zero_param_6,
	.param .b64 tensor_rhs_zero_param_7,
	.param .b64 tensor_rhs_zero_param_8,
	.param .b64 tensor_rhs_zero_param_9
)                                       // @tensor_rhs_zero
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<25>;

// %bb.0:
	ld.param.b64 	%rd21, [tensor_rhs_zero_param_6];
	ld.param.b64 	%rd23, [tensor_rhs_zero_param_1];
	ld.param.b64 	%rd1, [tensor_rhs_zero_param_0];
	ld.param.b64 	%rd3, [tensor_rhs_zero_param_2];
	ld.param.b64 	%rd4, [tensor_rhs_zero_param_3];
	ld.param.b64 	%rd5, [tensor_rhs_zero_param_4];
	mov.b64 	%rd2, %rd23;
	mov.b64 	%rd22, 0;
	mov.b64 	%rd20, %rd23;
$L__BB1_1:                              // =>This Inner Loop Header: Depth=1
	setp.gt.s64 	%p1, %rd22, 3;
	@%p1 bra 	$L__BB1_3;
// %bb.2:                               //   in Loop: Header=BB1_1 Depth=1
	ld.b32 	%r3, [%rd20];
	ld.b32 	%r4, [%rd21];
	add.rn.f32 	%r5, %r3, %r4;
	st.b32 	[%rd20], %r5;
	add.s64 	%rd22, %rd22, 1;
	add.s64 	%rd21, %rd21, 4;
	add.s64 	%rd20, %rd20, 4;
	bra.uni 	$L__BB1_1;
$L__BB1_3:
	mov.b64 	%rd24, 0;
$L__BB1_4:                              // =>This Inner Loop Header: Depth=1
	setp.gt.s64 	%p2, %rd24, 3;
	@%p2 bra 	$L__BB1_6;
// %bb.5:                               //   in Loop: Header=BB1_4 Depth=1
	ld.b32 	%r1, [%rd23];
	max.NaN.f32 	%r2, %r1, 0f00000000;
	st.b32 	[%rd23], %r2;
	add.s64 	%rd24, %rd24, 1;
	add.s64 	%rd23, %rd23, 4;
	bra.uni 	$L__BB1_4;
$L__BB1_6:
	st.param.b64 	[func_retval0], %rd1;
	st.param.b64 	[func_retval0+8], %rd2;
	st.param.b64 	[func_retval0+16], %rd3;
	st.param.b64 	[func_retval0+24], %rd4;
	st.param.b64 	[func_retval0+32], %rd5;
	ret;
                                        // -- End function
}
	// .globl	_mlir_ciface_tensor_rhs_zero // -- Begin function _mlir_ciface_tensor_rhs_zero
.visible .func _mlir_ciface_tensor_rhs_zero(
	.param .b64 _mlir_ciface_tensor_rhs_zero_param_0,
	.param .b64 _mlir_ciface_tensor_rhs_zero_param_1,
	.param .b64 _mlir_ciface_tensor_rhs_zero_param_2
)                                       // @_mlir_ciface_tensor_rhs_zero
{
	.reg .b64 	%rd<24>;

// %bb.0:
	ld.param.b64 	%rd1, [_mlir_ciface_tensor_rhs_zero_param_0];
	ld.param.b64 	%rd2, [_mlir_ciface_tensor_rhs_zero_param_1];
	ld.b64 	%rd3, [%rd2];
	ld.b64 	%rd4, [%rd2+8];
	ld.b64 	%rd5, [%rd2+16];
	ld.b64 	%rd6, [%rd2+24];
	ld.b64 	%rd7, [%rd2+32];
	ld.param.b64 	%rd8, [_mlir_ciface_tensor_rhs_zero_param_2];
	ld.b64 	%rd9, [%rd8];
	ld.b64 	%rd10, [%rd8+8];
	ld.b64 	%rd11, [%rd8+16];
	ld.b64 	%rd12, [%rd8+24];
	ld.b64 	%rd13, [%rd8+32];
	{ // callseq 0, 0
	.param .b64 	param0;
	.param .b64 	param1;
	.param .b64 	param2;
	.param .b64 	param3;
	.param .b64 	param4;
	.param .b64 	param5;
	.param .b64 	param6;
	.param .b64 	param7;
	.param .b64 	param8;
	.param .b64 	param9;
	.param .align 8 .b8 	retval0[40];
	st.param.b64 	[param9], %rd13;
	st.param.b64 	[param8], %rd12;
	st.param.b64 	[param7], %rd11;
	st.param.b64 	[param6], %rd10;
	st.param.b64 	[param5], %rd9;
	st.param.b64 	[param4], %rd7;
	st.param.b64 	[param3], %rd6;
	st.param.b64 	[param2], %rd5;
	st.param.b64 	[param1], %rd4;
	st.param.b64 	[param0], %rd3;
	call.uni (retval0), tensor_rhs_zero, (param0, param1, param2, param3, param4, param5, param6, param7, param8, param9);
	ld.param.b64 	%rd14, [retval0+32];
	ld.param.b64 	%rd15, [retval0+24];
	ld.param.b64 	%rd16, [retval0+16];
	ld.param.b64 	%rd17, [retval0+8];
	ld.param.b64 	%rd18, [retval0];
	} // callseq 0
	st.b64 	[%rd1+32], %rd14;
	st.b64 	[%rd1+24], %rd15;
	st.b64 	[%rd1+16], %rd16;
	st.b64 	[%rd1+8], %rd17;
	st.b64 	[%rd1], %rd18;
	ret;
                                        // -- End function
}
	// .globl	tensor_lhs_zero         // -- Begin function tensor_lhs_zero
.visible .func  (.param .align 8 .b8 func_retval0[40]) tensor_lhs_zero(
	.param .b64 tensor_lhs_zero_param_0,
	.param .b64 tensor_lhs_zero_param_1,
	.param .b64 tensor_lhs_zero_param_2,
	.param .b64 tensor_lhs_zero_param_3,
	.param .b64 tensor_lhs_zero_param_4,
	.param .b64 tensor_lhs_zero_param_5,
	.param .b64 tensor_lhs_zero_param_6,
	.param .b64 tensor_lhs_zero_param_7,
	.param .b64 tensor_lhs_zero_param_8,
	.param .b64 tensor_lhs_zero_param_9
)                                       // @tensor_lhs_zero
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<25>;

// %bb.0:
	ld.param.b64 	%rd21, [tensor_lhs_zero_param_6];
	ld.param.b64 	%rd23, [tensor_lhs_zero_param_1];
	ld.param.b64 	%rd1, [tensor_lhs_zero_param_0];
	ld.param.b64 	%rd3, [tensor_lhs_zero_param_2];
	ld.param.b64 	%rd4, [tensor_lhs_zero_param_3];
	ld.param.b64 	%rd5, [tensor_lhs_zero_param_4];
	mov.b64 	%rd2, %rd23;
	mov.b64 	%rd22, 0;
	mov.b64 	%rd20, %rd23;
$L__BB3_1:                              // =>This Inner Loop Header: Depth=1
	setp.gt.s64 	%p1, %rd22, 3;
	@%p1 bra 	$L__BB3_3;
// %bb.2:                               //   in Loop: Header=BB3_1 Depth=1
	ld.b32 	%r3, [%rd20];
	ld.b32 	%r4, [%rd21];
	add.rn.f32 	%r5, %r3, %r4;
	st.b32 	[%rd20], %r5;
	add.s64 	%rd22, %rd22, 1;
	add.s64 	%rd21, %rd21, 4;
	add.s64 	%rd20, %rd20, 4;
	bra.uni 	$L__BB3_1;
$L__BB3_3:
	mov.b64 	%rd24, 0;
$L__BB3_4:                              // =>This Inner Loop Header: Depth=1
	setp.gt.s64 	%p2, %rd24, 3;
	@%p2 bra 	$L__BB3_6;
// %bb.5:                               //   in Loop: Header=BB3_4 Depth=1
	ld.b32 	%r1, [%rd23];
	max.NaN.f32 	%r2, %r1, 0f00000000;
	st.b32 	[%rd23], %r2;
	add.s64 	%rd24, %rd24, 1;
	add.s64 	%rd23, %rd23, 4;
	bra.uni 	$L__BB3_4;
$L__BB3_6:
	st.param.b64 	[func_retval0], %rd1;
	st.param.b64 	[func_retval0+8], %rd2;
	st.param.b64 	[func_retval0+16], %rd3;
	st.param.b64 	[func_retval0+24], %rd4;
	st.param.b64 	[func_retval0+32], %rd5;
	ret;
                                        // -- End function
}
	// .globl	_mlir_ciface_tensor_lhs_zero // -- Begin function _mlir_ciface_tensor_lhs_zero
.visible .func _mlir_ciface_tensor_lhs_zero(
	.param .b64 _mlir_ciface_tensor_lhs_zero_param_0,
	.param .b64 _mlir_ciface_tensor_lhs_zero_param_1,
	.param .b64 _mlir_ciface_tensor_lhs_zero_param_2
)                                       // @_mlir_ciface_tensor_lhs_zero
{
	.reg .b64 	%rd<24>;

// %bb.0:
	ld.param.b64 	%rd1, [_mlir_ciface_tensor_lhs_zero_param_0];
	ld.param.b64 	%rd2, [_mlir_ciface_tensor_lhs_zero_param_1];
	ld.b64 	%rd3, [%rd2];
	ld.b64 	%rd4, [%rd2+8];
	ld.b64 	%rd5, [%rd2+16];
	ld.b64 	%rd6, [%rd2+24];
	ld.b64 	%rd7, [%rd2+32];
	ld.param.b64 	%rd8, [_mlir_ciface_tensor_lhs_zero_param_2];
	ld.b64 	%rd9, [%rd8];
	ld.b64 	%rd10, [%rd8+8];
	ld.b64 	%rd11, [%rd8+16];
	ld.b64 	%rd12, [%rd8+24];
	ld.b64 	%rd13, [%rd8+32];
	{ // callseq 1, 0
	.param .b64 	param0;
	.param .b64 	param1;
	.param .b64 	param2;
	.param .b64 	param3;
	.param .b64 	param4;
	.param .b64 	param5;
	.param .b64 	param6;
	.param .b64 	param7;
	.param .b64 	param8;
	.param .b64 	param9;
	.param .align 8 .b8 	retval0[40];
	st.param.b64 	[param9], %rd13;
	st.param.b64 	[param8], %rd12;
	st.param.b64 	[param7], %rd11;
	st.param.b64 	[param6], %rd10;
	st.param.b64 	[param5], %rd9;
	st.param.b64 	[param4], %rd7;
	st.param.b64 	[param3], %rd6;
	st.param.b64 	[param2], %rd5;
	st.param.b64 	[param1], %rd4;
	st.param.b64 	[param0], %rd3;
	call.uni (retval0), tensor_lhs_zero, (param0, param1, param2, param3, param4, param5, param6, param7, param8, param9);
	ld.param.b64 	%rd14, [retval0+32];
	ld.param.b64 	%rd15, [retval0+24];
	ld.param.b64 	%rd16, [retval0+16];
	ld.param.b64 	%rd17, [retval0+8];
	ld.param.b64 	%rd18, [retval0];
	} // callseq 1
	st.b64 	[%rd1+32], %rd14;
	st.b64 	[%rd1+24], %rd15;
	st.b64 	[%rd1+16], %rd16;
	st.b64 	[%rd1+8], %rd17;
	st.b64 	[%rd1], %rd18;
	ret;
                                        // -- End function
}
